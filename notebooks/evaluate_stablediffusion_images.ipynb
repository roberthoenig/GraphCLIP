{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Stable Diffusion Images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import relational_image_generation_evaluation as rige\n",
    "ROOT_PATH = os.path.join(os.getcwd(), '..')\n",
    "EVALUATION_PATH = os.path.join(ROOT_PATH, 'datasets', 'evaluations', 'CC-500')\n",
    "TO_EVALUATE = ['fa_maps-l', 'base-l', 'fa-acc_maps-l']\n",
    "CC500 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached filtered graphs\n",
      "Filtered out 254 graphs\n",
      "Number of graphs: 349\n",
      "The first graph has nodes: ['bench', 'car'], node attributes: [['green'], ['red']], and edge predicates: ['and', 'and']\n"
     ]
    }
   ],
   "source": [
    "import relational_image_generation_evaluation as rige\n",
    "if not CC500:\n",
    "    adv_dataset = rige.get_adversarial_attribute_dataset()\n",
    "    orig_prompts, adv_prompts = rige.get_adv_prompt_list('attributes')\n",
    "    for prompt, graph_dict in zip(orig_prompts, adv_dataset):\n",
    "        assert prompt.split(' ')[0] in graph_dict['original_graph'].caption\n",
    "    index_to_graph_dict = {i: graph_dict for i, graph_dict in enumerate(adv_dataset)}\n",
    "else:\n",
    "    adv_dataloader = rige.get_cc500_graph_dataloader()\n",
    "    adv_dataset = adv_dataloader.dataset\n",
    "    index_to_graph_dict = {i: graph_dict for i, graph_dict in enumerate(adv_dataset)}\n",
    "    # filter out graphs with names or predicates not in rige.FILTERED_OBJECTS, rige.FILTERED_ATTRIBUTES, rige.FILTERED_RELATIONSHIPS\n",
    "    for i in list(index_to_graph_dict.keys()):\n",
    "        graph = index_to_graph_dict[i]\n",
    "        if not all([ graph.nodes[n]['name'] in rige.FILTERED_OBJECTS for n in graph.nodes]):\n",
    "            del index_to_graph_dict[i]\n",
    "            continue\n",
    "        if not all([ graph.edges[e]['predicate'] in rige.FILTERED_RELATIONSHIPS for e in graph.edges]):\n",
    "            del index_to_graph_dict[i]\n",
    "            continue\n",
    "        if not all([ graph.nodes[n]['attributes'][i] in rige.FILTERED_ATTRIBUTES for n in graph.nodes for i in range(len(graph.nodes[n]['attributes']))]):\n",
    "            del index_to_graph_dict[i]\n",
    "            continue\n",
    "\n",
    "    \n",
    "    print(f'Filtered out {len(adv_dataset) - len(index_to_graph_dict)} graphs')\n",
    "    print(f'Number of graphs: {len(index_to_graph_dict)}')\n",
    "    first_graph = index_to_graph_dict[0]\n",
    "    fg_node_names = [first_graph.nodes[n]['name'] for n in first_graph.nodes]\n",
    "    fg_node_attributes = [first_graph.nodes[n]['attributes'] for n in first_graph.nodes]\n",
    "    fg_edge_predicates = [first_graph.edges[e]['predicate'] for e in first_graph.edges]\n",
    "    print(f'The first graph has nodes: {fg_node_names}, node attributes: {fg_node_attributes}, and edge predicates: {fg_edge_predicates}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3110\n",
      "3110\n",
      "3110\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>seed</th>\n",
       "      <th>resolution</th>\n",
       "      <th>modelname</th>\n",
       "      <th>image_path</th>\n",
       "      <th>graph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202</td>\n",
       "      <td>7122</td>\n",
       "      <td>II</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>48907</td>\n",
       "      <td>II</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>68319</td>\n",
       "      <td>II</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>8255</td>\n",
       "      <td>II</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246</td>\n",
       "      <td>68245</td>\n",
       "      <td>II</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9325</th>\n",
       "      <td>51</td>\n",
       "      <td>54235</td>\n",
       "      <td>II</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9326</th>\n",
       "      <td>350</td>\n",
       "      <td>47153</td>\n",
       "      <td>I</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9327</th>\n",
       "      <td>431</td>\n",
       "      <td>52383</td>\n",
       "      <td>I</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9328</th>\n",
       "      <td>52</td>\n",
       "      <td>14592</td>\n",
       "      <td>I</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9329</th>\n",
       "      <td>115</td>\n",
       "      <td>81643</td>\n",
       "      <td>II</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>/local/home/jthomm/GraphCLIP/notebooks/../data...</td>\n",
       "      <td>(1, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9330 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index   seed resolution      modelname  \\\n",
       "0       202   7122         II      fa_maps-l   \n",
       "1        28  48907         II      fa_maps-l   \n",
       "2        90  68319         II      fa_maps-l   \n",
       "3        89   8255         II      fa_maps-l   \n",
       "4       246  68245         II      fa_maps-l   \n",
       "...     ...    ...        ...            ...   \n",
       "9325     51  54235         II  fa-acc_maps-l   \n",
       "9326    350  47153          I  fa-acc_maps-l   \n",
       "9327    431  52383          I  fa-acc_maps-l   \n",
       "9328     52  14592          I  fa-acc_maps-l   \n",
       "9329    115  81643         II  fa-acc_maps-l   \n",
       "\n",
       "                                             image_path   graph  \n",
       "0     /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "1     /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "2     /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "3     /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "4     /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "...                                                 ...     ...  \n",
       "9325  /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "9326  /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "9327  /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "9328  /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "9329  /local/home/jthomm/GraphCLIP/notebooks/../data...  (1, 2)  \n",
       "\n",
       "[9330 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9330, 6)\n",
      "<class 'networkx.classes.digraph.DiGraph'>\n"
     ]
    }
   ],
   "source": [
    "def get_stablediffusion_images(image_folder_path, modelname):\n",
    "    images = []\n",
    "    for image_path in os.listdir(image_folder_path):\n",
    "        if not image_path.endswith('.png'):\n",
    "            continue\n",
    "        # the image name has the form: index-og/adv_seed_I/II.png. We extract the index, og/adv, seed and I/II\n",
    "        index = int(image_path.split('-')[0])\n",
    "        og_adv = image_path.split('-')[1].split('_')[0]\n",
    "        seed = image_path.split('_')[1]\n",
    "        resolution = image_path.split('_')[2].split('.')[0]\n",
    "        image_path = os.path.join(image_folder_path, image_path)\n",
    "        # add the image to the dataframe\n",
    "        images.append({\n",
    "            'index': index, \n",
    "            'og_adv': og_adv, \n",
    "            'seed': seed, \n",
    "            'resolution': resolution, \n",
    "            'modelname': modelname, \n",
    "            'image_path': image_path,\n",
    "            'original_graph': index_to_graph_dict[(index)]['original_graph'],\n",
    "            'adv_graph': index_to_graph_dict[(index)]['adv_graph'],\n",
    "        })\n",
    "    print(len(images))\n",
    "    return images\n",
    "def get_stablediffusion_images_cc500(image_folder_path, modelname):\n",
    "    images = []\n",
    "    for image_path in os.listdir(image_folder_path):\n",
    "        if not image_path.endswith('.png'):\n",
    "            continue\n",
    "        # the image name has the form: index_seed_I/II.png. We extract the index, seed and I/II\n",
    "        index = int(image_path.split('_')[0])\n",
    "        if index not in index_to_graph_dict:\n",
    "            continue\n",
    "        seed = image_path.split('_')[1]\n",
    "        resolution = image_path.split('_')[2].split('.')[0]\n",
    "        image_path = os.path.join(image_folder_path, image_path)\n",
    "        # add the image to the dataframe\n",
    "        images.append({\n",
    "            'index': index, \n",
    "            'seed': seed, \n",
    "            'resolution': resolution, \n",
    "            'modelname': modelname, \n",
    "            'image_path': image_path,\n",
    "            'graph': index_to_graph_dict[(index)],\n",
    "        })\n",
    "    print(len(images))\n",
    "    return images\n",
    "all_images = []\n",
    "for foldername in TO_EVALUATE:\n",
    "    path = os.path.join(EVALUATION_PATH, foldername)\n",
    "    if CC500:\n",
    "        dictlist = get_stablediffusion_images_cc500(path, foldername)\n",
    "    else:\n",
    "        dictlist = get_stablediffusion_images(path, foldername)\n",
    "    all_images += dictlist\n",
    "# convert the dictlist to a dataframe\n",
    "all_images = pd.DataFrame(all_images)\n",
    "display(all_images)\n",
    "print(all_images.shape)\n",
    "# print the type of the original graph in the first row\n",
    "if not CC500:\n",
    "    print(type(all_images['original_graph'][0]))\n",
    "else:\n",
    "    print(type(all_images['graph'][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Method\n",
    "We evaluate with the following method: We take the original graph and check if the original prompt image resembles it better than the adversarial prompt image.\n",
    "\n",
    "That means, for each original prompt (i.e. for each index), we check the two images. We do this first only for low resolution and for each modelname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on 311 indexes\n",
      "max index: 536\n",
      "min index: 0\n",
      "missing indexes from 0 to inclusive 100: {40, 41}\n"
     ]
    }
   ],
   "source": [
    "# get all indexes in the dataframe\n",
    "indexes = all_images['index'].unique()\n",
    "print('Evaluation on {} indexes'.format(len(indexes)))\n",
    "print(\"max index: {}\".format(max(indexes)))\n",
    "print(\"min index: {}\".format(min(indexes)))\n",
    "print(\"missing indexes from 0 to inclusive 100: {}\".format(set(range(101)) - set(indexes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "def get_image_score(evaluator, graph, image_paths):\n",
    "    # load the image\n",
    "    images = []\n",
    "    for image_path in image_paths:\n",
    "        image = Image.open(image_path)\n",
    "        images.append(image)\n",
    "    # evaluate the image\n",
    "    scores = evaluator(images, [graph for _ in range(len(images))])['attr_scores']\n",
    "    # get the mean score\n",
    "    # score = np.mean(scores)\n",
    "    return scores\n",
    "\n",
    "def get_scores(evaluator, modelname, resolution):\n",
    "    # get all images with the given modelname and resolution\n",
    "    images = all_images[(all_images['modelname'] == modelname) & (all_images['resolution'] == resolution)]\n",
    "    # get all indexes\n",
    "    indexes = images['index'].unique()\n",
    "    # get the accuracy for each index\n",
    "    scores = []\n",
    "    for index in indexes:\n",
    "        # get the original graph\n",
    "        if not CC500:\n",
    "            original_graph = images[images['index'] == index]['original_graph']\n",
    "            assert len(set(g.caption for g in original_graph)) == 1\n",
    "            original_graph = original_graph.iloc[0]\n",
    "            adv_graph = images[images['index'] == index]['adv_graph'].iloc[0]\n",
    "            # get the image paths, with different seeds\n",
    "            og_image_paths = images[(images['index'] == index) & (images['og_adv'] == 'og')]['image_path'].values\n",
    "            adv_image_paths = images[(images['index'] == index) & (images['og_adv'] == 'adv')]['image_path'].values\n",
    "            # get the scores\n",
    "            orig_graph_orig_img = get_image_score(evaluator, original_graph, og_image_paths)\n",
    "            adv_graph_orig_img = get_image_score(evaluator, adv_graph, og_image_paths)\n",
    "            orig_graph_adv_img = get_image_score(evaluator, original_graph, adv_image_paths)\n",
    "            adv_graph_adv_img = get_image_score(evaluator, adv_graph, adv_image_paths)\n",
    "            # get the accuracy\n",
    "            scores.append({\n",
    "                'index': index,\n",
    "                'modelname': modelname,\n",
    "                'resolution': resolution,\n",
    "                'orig_graph_orig_img': orig_graph_orig_img,\n",
    "                'orig_graph_adv_img': orig_graph_adv_img,\n",
    "                'adv_graph_orig_img': adv_graph_orig_img,\n",
    "                'adv_graph_adv_img': adv_graph_adv_img,\n",
    "            })\n",
    "        else:\n",
    "            graph = images[images['index'] == index]['graph'].iloc[0]\n",
    "            # get the image paths, with different seeds\n",
    "            image_paths = images[(images['index'] == index)]['image_path'].values\n",
    "            # get the scores\n",
    "            graph_orig_img = get_image_score(evaluator, graph, image_paths)\n",
    "            # get the accuracy\n",
    "            scores.append({\n",
    "                'index': index,\n",
    "                'modelname': modelname,\n",
    "                'resolution': resolution,\n",
    "                'graph_orig_img': graph_orig_img,\n",
    "            })\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:2 for evaluation.\n",
      "Using text embeddings as input to the model.\n"
     ]
    }
   ],
   "source": [
    "local_weights_path = '/local/home/jthomm/GraphCLIP/experiments/2023-06-24/vision_transformer_8/model_epoch-v9.ckpt'\n",
    "evaluator = rige.Evaluator('ViT-L/14', model_weights_path=local_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with fa_maps-l I\n",
      "Done with fa_maps-l II\n",
      "Done with base-l I\n",
      "Done with base-l II\n",
      "Done with fa-acc_maps-l I\n",
      "Done with fa-acc_maps-l II\n"
     ]
    }
   ],
   "source": [
    "score_dict = []\n",
    "for modelname in TO_EVALUATE:\n",
    "    for resolution in ['I', 'II']:\n",
    "        scores = get_scores(evaluator, modelname, resolution)\n",
    "        score_dict += scores\n",
    "        print('Done with {} {}'.format(modelname, resolution))\n",
    "# convert the dict to a dataframe\n",
    "score_df = pd.DataFrame(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>modelname</th>\n",
       "      <th>resolution</th>\n",
       "      <th>graph_orig_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.5008031725883484, 0.682695209980011, 0.5265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>185</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.41138994693756104, 0.09675640612840652, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.14894235134124756, 0.5421763062477112, 0.14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.22690221667289734, 0.1112748384475708, 0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>404</td>\n",
       "      <td>fa_maps-l</td>\n",
       "      <td>I</td>\n",
       "      <td>[0.897138237953186, 0.06140827387571335, 0.516...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>411</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>II</td>\n",
       "      <td>[0.3230156898498535, 0.3562612533569336, 0.448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>63</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>II</td>\n",
       "      <td>[0.2874911427497864, 0.388953298330307, 0.4739...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>70</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>II</td>\n",
       "      <td>[0.4611344635486603, 0.446847140789032, 0.4353...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>72</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>II</td>\n",
       "      <td>[0.46789029240608215, 0.4461095631122589, 0.38...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1865</th>\n",
       "      <td>55</td>\n",
       "      <td>fa-acc_maps-l</td>\n",
       "      <td>II</td>\n",
       "      <td>[0.004174324683845043, 0.3489799201488495, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1866 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index      modelname resolution  \\\n",
       "0       166      fa_maps-l          I   \n",
       "1       185      fa_maps-l          I   \n",
       "2        33      fa_maps-l          I   \n",
       "3       145      fa_maps-l          I   \n",
       "4       404      fa_maps-l          I   \n",
       "...     ...            ...        ...   \n",
       "1861    411  fa-acc_maps-l         II   \n",
       "1862     63  fa-acc_maps-l         II   \n",
       "1863     70  fa-acc_maps-l         II   \n",
       "1864     72  fa-acc_maps-l         II   \n",
       "1865     55  fa-acc_maps-l         II   \n",
       "\n",
       "                                         graph_orig_img  \n",
       "0     [0.5008031725883484, 0.682695209980011, 0.5265...  \n",
       "1     [0.41138994693756104, 0.09675640612840652, 0.0...  \n",
       "2     [0.14894235134124756, 0.5421763062477112, 0.14...  \n",
       "3     [0.22690221667289734, 0.1112748384475708, 0.08...  \n",
       "4     [0.897138237953186, 0.06140827387571335, 0.516...  \n",
       "...                                                 ...  \n",
       "1861  [0.3230156898498535, 0.3562612533569336, 0.448...  \n",
       "1862  [0.2874911427497864, 0.388953298330307, 0.4739...  \n",
       "1863  [0.4611344635486603, 0.446847140789032, 0.4353...  \n",
       "1864  [0.46789029240608215, 0.4461095631122589, 0.38...  \n",
       "1865  [0.004174324683845043, 0.3489799201488495, 0.0...  \n",
       "\n",
       "[1866 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the dataframe\n",
    "NAME = 'stablediffusion_scores_cc500_datacomp'\n",
    "display(score_df)\n",
    "score_df.to_csv(os.path.join(EVALUATION_PATH, f'{NAME}.csv'), index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We calculate**\n",
    " * are images getting closer to the prompt attributes they were generated with? (both original, adversarial). Avg score and accuracy (between models)\n",
    " * are images closer to the prompt attributes they were generated with compared to the wrong attributes? Avg difference and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [0.5008031725883484, 0.682695209980011, 0.5265...\n",
       "1      [0.41138994693756104, 0.09675640612840652, 0.0...\n",
       "2      [0.14894235134124756, 0.5421763062477112, 0.14...\n",
       "3      [0.22690221667289734, 0.1112748384475708, 0.08...\n",
       "4      [0.897138237953186, 0.06140827387571335, 0.516...\n",
       "                             ...                        \n",
       "306    [0.35735902190208435, 0.3852696716785431, 0.45...\n",
       "307    [0.8107014298439026, 0.4438059329986572, 0.111...\n",
       "308    [0.47578561305999756, 0.4866176247596741, 0.44...\n",
       "309    [0.13153913617134094, 0.4637344479560852, 0.02...\n",
       "310    [0.6270792484283447, 0.8730216026306152, 0.495...\n",
       "Name: graph_orig_img, Length: 311, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = score_df[(score_df['modelname'] == TO_EVALUATE[0]) & (score_df['resolution'] == 'I')]\n",
    "if not CC500:\n",
    "    display(scores['orig_graph_orig_img'])\n",
    "    display(scores['orig_graph_adv_img'])\n",
    "else:\n",
    "    display(scores['graph_orig_img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelname: fa_maps-l, resolution: I\n",
      "Modelname: fa_maps-l, resolution: II\n",
      "Modelname: base-l, resolution: I\n",
      "Modelname: base-l, resolution: II\n",
      "Modelname: fa-acc_maps-l, resolution: I\n",
      "Modelname: fa-acc_maps-l, resolution: II\n"
     ]
    }
   ],
   "source": [
    "# using the scoredf, we can now plot the results\n",
    "evaluation_results = {}\n",
    "\n",
    "def flatten(name, substitute_scores=None):\n",
    "    if substitute_scores is not None:\n",
    "        return np.array(list(substitute_scores[name].values)).reshape(-1)\n",
    "    return np.array(list(scores[name].values)).reshape(-1)\n",
    "\n",
    "for modelname in TO_EVALUATE:\n",
    "    for resolution in ['I', 'II']:\n",
    "        if not CC500:\n",
    "            scores =          score_df[(score_df['modelname'] == modelname) & (score_df['resolution'] == resolution)]\n",
    "            scores_baseline = score_df[(score_df['modelname'] == 'base-l') & (score_df['resolution'] == resolution)]\n",
    "            print('Modelname: {}, resolution: {}'.format(modelname, resolution))\n",
    "            avg_score_origimg_to_origprompt = flatten('orig_graph_orig_img').mean()\n",
    "            \n",
    "            avg_score_advimg_to_advprompt = flatten('adv_graph_adv_img').mean()\n",
    "\n",
    "            # for the origimage: for each image, subtract score origprompt - score advprompt. Then take the mean. Take care to always subtract the same index\n",
    "\n",
    "            \n",
    "            avg_promptdiff_origimg = flatten('orig_graph_orig_img') - flatten('adv_graph_orig_img')\n",
    "            acc_promptdiff_origimg = (avg_promptdiff_origimg > 0).mean()\n",
    "            avg_promptdiff_origimg = avg_promptdiff_origimg.mean()\n",
    "\n",
    "            avg_promptdiff_advimg = flatten('adv_graph_adv_img') - flatten('orig_graph_adv_img')\n",
    "            acc_promptdiff_advimg = (avg_promptdiff_advimg > 0).mean()\n",
    "            avg_promptdiff_advimg = avg_promptdiff_advimg.mean()\n",
    "\n",
    "            acc_origprompt_rightimgbetter = (flatten('orig_graph_orig_img')>flatten('orig_graph_adv_img')).mean()\n",
    "            acc_advprompt_rightimgbetter = (flatten('adv_graph_adv_img')>flatten('adv_graph_orig_img')).mean()\n",
    "\n",
    "            acc_to_baseline_origimg = (flatten('orig_graph_orig_img')>flatten('orig_graph_orig_img', scores_baseline)).mean()\n",
    "            acc_to_baseline_advimg = (flatten('adv_graph_adv_img')>flatten('adv_graph_adv_img', scores_baseline)).mean()\n",
    "\n",
    "            evaluation_results[(modelname, resolution)] = {\n",
    "                'avg_score_origimg_to_origprompt': avg_score_origimg_to_origprompt,\n",
    "                'avg_score_advimg_to_advprompt': avg_score_advimg_to_advprompt,\n",
    "                'avg_prompt_diff_origimg': avg_promptdiff_origimg,\n",
    "                'avg_prompt_diff_advimg': avg_promptdiff_advimg,\n",
    "                'acc_rightpromptbetter_origimg': acc_promptdiff_origimg,\n",
    "                'acc_rightpromptbetter_advimg': acc_promptdiff_advimg,\n",
    "                'acc_origprompt_rightimgbetter': acc_origprompt_rightimgbetter,\n",
    "                'acc_advprompt_rightimgbetter': acc_advprompt_rightimgbetter,\n",
    "                'acc_betterthan_baseline_origimg': acc_to_baseline_origimg,\n",
    "                'acc_betterthan_baseline_advimg': acc_to_baseline_advimg,\n",
    "            }\n",
    "        else:\n",
    "            scores =          score_df[(score_df['modelname'] == modelname) & (score_df['resolution'] == resolution)]\n",
    "            scores_baseline = score_df[(score_df['modelname'] == 'base-l') & (score_df['resolution'] == resolution)]\n",
    "            print('Modelname: {}, resolution: {}'.format(modelname, resolution))\n",
    "            avg_score_img_to_prompt = flatten('graph_orig_img').mean()\n",
    "\n",
    "            # for the origimage: for each image, subtract score origprompt - score advprompt. Then take the mean. Take care to always subtract the same index\n",
    "\n",
    "            acc_to_baseline_origimg = (flatten('graph_orig_img')>flatten('graph_orig_img', scores_baseline)).mean()\n",
    "\n",
    "            evaluation_results[(modelname, resolution)] = {\n",
    "                'avg_score_img_to_prompt': avg_score_img_to_prompt,\n",
    "                'acc_betterthan_baseline_origimg': acc_to_baseline_origimg,\n",
    "            }\n",
    "results = pd.DataFrame(evaluation_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>avg_score_img_to_prompt</th>\n",
       "      <th>acc_betterthan_baseline_origimg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fa_maps-l</th>\n",
       "      <th>I</th>\n",
       "      <td>0.451312</td>\n",
       "      <td>0.572347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>0.437969</td>\n",
       "      <td>0.565273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">base-l</th>\n",
       "      <th>I</th>\n",
       "      <td>0.408596</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>0.399803</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">fa-acc_maps-l</th>\n",
       "      <th>I</th>\n",
       "      <td>0.428290</td>\n",
       "      <td>0.571704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>II</th>\n",
       "      <td>0.415928</td>\n",
       "      <td>0.552412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  avg_score_img_to_prompt  acc_betterthan_baseline_origimg\n",
       "fa_maps-l     I                  0.451312                         0.572347\n",
       "              II                 0.437969                         0.565273\n",
       "base-l        I                  0.408596                         0.000000\n",
       "              II                 0.399803                         0.000000\n",
       "fa-acc_maps-l I                  0.428290                         0.571704\n",
       "              II                 0.415928                         0.552412"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results to /local/home/jthomm/GraphCLIP/notebooks/../datasets/evaluations/CC-500/stablediffusion_scores_cc500_datacomp.csv\n"
     ]
    }
   ],
   "source": [
    "display(results)\n",
    "# save the results\n",
    "results.round(2).to_csv(os.path.join(EVALUATION_PATH, f'{NAME}.csv'))\n",
    "print('Saved results to {}'.format(os.path.join(EVALUATION_PATH, f'{NAME}.csv')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>avg_score_origimg_to_origprompt</th>\n",
       "      <th>avg_score_advimg_to_advprompt</th>\n",
       "      <th>avg_prompt_diff_origimg</th>\n",
       "      <th>avg_prompt_diff_advimg</th>\n",
       "      <th>acc_rightpromptbetter_origimg</th>\n",
       "      <th>acc_rightpromptbetter_advimg</th>\n",
       "      <th>acc_origprompt_rightimgbetter</th>\n",
       "      <th>acc_advprompt_rightimgbetter</th>\n",
       "      <th>acc_betterthan_baseline_origimg</th>\n",
       "      <th>acc_betterthan_baseline_advimg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fa_maps-l</th>\n",
       "      <td>I</td>\n",
       "      <td>0.417946</td>\n",
       "      <td>0.365815</td>\n",
       "      <td>0.233280</td>\n",
       "      <td>0.134635</td>\n",
       "      <td>0.795506</td>\n",
       "      <td>0.624719</td>\n",
       "      <td>0.759551</td>\n",
       "      <td>0.777528</td>\n",
       "      <td>0.521348</td>\n",
       "      <td>0.541573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa_maps-l</th>\n",
       "      <td>II</td>\n",
       "      <td>0.417944</td>\n",
       "      <td>0.367578</td>\n",
       "      <td>0.237425</td>\n",
       "      <td>0.134765</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.635955</td>\n",
       "      <td>0.759551</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>0.534831</td>\n",
       "      <td>0.568539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-l</th>\n",
       "      <td>I</td>\n",
       "      <td>0.408328</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.206241</td>\n",
       "      <td>0.085719</td>\n",
       "      <td>0.766292</td>\n",
       "      <td>0.559551</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.725843</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base-l</th>\n",
       "      <td>II</td>\n",
       "      <td>0.405703</td>\n",
       "      <td>0.342797</td>\n",
       "      <td>0.202878</td>\n",
       "      <td>0.083703</td>\n",
       "      <td>0.741573</td>\n",
       "      <td>0.579775</td>\n",
       "      <td>0.737079</td>\n",
       "      <td>0.692135</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa-acc_maps-l</th>\n",
       "      <td>I</td>\n",
       "      <td>0.408155</td>\n",
       "      <td>0.357213</td>\n",
       "      <td>0.227327</td>\n",
       "      <td>0.116546</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.757303</td>\n",
       "      <td>0.773034</td>\n",
       "      <td>0.489888</td>\n",
       "      <td>0.521348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fa-acc_maps-l</th>\n",
       "      <td>II</td>\n",
       "      <td>0.409692</td>\n",
       "      <td>0.356338</td>\n",
       "      <td>0.227978</td>\n",
       "      <td>0.120340</td>\n",
       "      <td>0.766292</td>\n",
       "      <td>0.613483</td>\n",
       "      <td>0.716854</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>0.541573</td>\n",
       "      <td>0.550562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 1  avg_score_origimg_to_origprompt  \\\n",
       "fa_maps-l              I                         0.417946   \n",
       "fa_maps-l             II                         0.417944   \n",
       "base-l                 I                         0.408328   \n",
       "base-l                II                         0.405703   \n",
       "fa-acc_maps-l          I                         0.408155   \n",
       "fa-acc_maps-l         II                         0.409692   \n",
       "\n",
       "               avg_score_advimg_to_advprompt  avg_prompt_diff_origimg  \\\n",
       "fa_maps-l                           0.365815                 0.233280   \n",
       "fa_maps-l                           0.367578                 0.237425   \n",
       "base-l                              0.341877                 0.206241   \n",
       "base-l                              0.342797                 0.202878   \n",
       "fa-acc_maps-l                       0.357213                 0.227327   \n",
       "fa-acc_maps-l                       0.356338                 0.227978   \n",
       "\n",
       "               avg_prompt_diff_advimg  acc_rightpromptbetter_origimg  \\\n",
       "fa_maps-l                    0.134635                       0.795506   \n",
       "fa_maps-l                    0.134765                       0.800000   \n",
       "base-l                       0.085719                       0.766292   \n",
       "base-l                       0.083703                       0.741573   \n",
       "fa-acc_maps-l                0.116546                       0.773034   \n",
       "fa-acc_maps-l                0.120340                       0.766292   \n",
       "\n",
       "               acc_rightpromptbetter_advimg  acc_origprompt_rightimgbetter  \\\n",
       "fa_maps-l                          0.624719                       0.759551   \n",
       "fa_maps-l                          0.635955                       0.759551   \n",
       "base-l                             0.559551                       0.741573   \n",
       "base-l                             0.579775                       0.737079   \n",
       "fa-acc_maps-l                      0.600000                       0.757303   \n",
       "fa-acc_maps-l                      0.613483                       0.716854   \n",
       "\n",
       "               acc_advprompt_rightimgbetter  acc_betterthan_baseline_origimg  \\\n",
       "fa_maps-l                          0.777528                         0.521348   \n",
       "fa_maps-l                          0.764045                         0.534831   \n",
       "base-l                             0.725843                         0.000000   \n",
       "base-l                             0.692135                         0.000000   \n",
       "fa-acc_maps-l                      0.773034                         0.489888   \n",
       "fa-acc_maps-l                      0.761798                         0.541573   \n",
       "\n",
       "               acc_betterthan_baseline_advimg  \n",
       "fa_maps-l                            0.541573  \n",
       "fa_maps-l                            0.568539  \n",
       "base-l                               0.000000  \n",
       "base-l                               0.000000  \n",
       "fa-acc_maps-l                        0.521348  \n",
       "fa-acc_maps-l                        0.550562  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load the results\n",
    "results = pd.read_csv(os.path.join(EVALUATION_PATH, f'stablediffusion_results_adv_attr.csv'), index_col=0)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaltestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
