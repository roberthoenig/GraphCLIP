{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage suggestions for this python package"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install the package:\n",
    "\n",
    "Activate the python environment you want to use. Go into the folder of this notebook, where setup.py located is, and run \n",
    "\n",
    "`pip install -e .`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/home/jthomm/anaconda3/envs/submissionenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import relational_image_generation_evaluation as rige"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cuda:6 for evaluation.\n",
      "Using text embeddings as input to the model.\n",
      "Loading filtered test graphs...\n",
      "Finished loading filtered test graphs\n",
      "Generating one edge graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 1102.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating one edge graphs\n",
      "Loading filtered test graphs...\n",
      "Finished loading filtered test graphs\n",
      "Generating two edge graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 855.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished generating two edge graphs\n",
      "len(dataloader_one): 837\n",
      "len(dataloader_two): 1076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluator = rige.Evaluator('ViT-L/14')\n",
    "# testonly just makes loading faster, to actually test the model you need to set testonly=False\n",
    "# this is not the test set or so. It's just a flag to make loading faster\n",
    "dataloader_one = rige.get_one_edge_dataloader(testonly=True)\n",
    "dataloader_two = rige.get_two_edge_dataloader(testonly=True)\n",
    "print(\"len(dataloader_one):\", len(dataloader_one))\n",
    "print(\"len(dataloader_two):\", len(dataloader_two))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dataloaders give you networkx graphs as they have convenient functionality.**\n",
    "\n",
    "**You can access all scene information like this (images have to be loaded using PATH_TO_VG/image_id.jpg):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nodes: [1025831, 1025835, 1025837]\n",
      "edges: [(1025835, 1025831), (1025837, 1025831)]\n",
      "some edge: (1025835, 1025831) edge predicate: on\n",
      "some node: 1025831 node label: table\n",
      "dict_keys(['w', 'h', 'x', 'y', 'attributes', 'name'])\n",
      "dict_keys(['synsets', 'relationship_id', 'predicate'])\n",
      "image_id: 93\n",
      "image dimensions: 335 500\n"
     ]
    }
   ],
   "source": [
    "some_graph = next(iter(dataloader_two))[0]\n",
    "print(\"nodes:\", some_graph.nodes)\n",
    "print(\"edges:\", some_graph.edges)\n",
    "edge = list(some_graph.edges)[0]\n",
    "print(\"some edge:\", edge, \"edge predicate:\", some_graph.edges[edge]['predicate'])\n",
    "node = list(some_graph.nodes)[0]\n",
    "print(\"some node:\", node, \"node label:\", some_graph.nodes[node]['name'])\n",
    "# other information:\n",
    "print(some_graph.nodes[node].keys())\n",
    "print(some_graph.edges[edge].keys())\n",
    "print(\"image_id:\", some_graph.image_id)\n",
    "print(\"image dimensions:\", some_graph.image_w, some_graph.image_h)\n",
    "# use this copy function to make a copy of the graph, because much faster than deepcopy and normal copy doesn't copy everything\n",
    "some_graph_copy = rige.copy_graph(some_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "images = []\n",
    "graphs = []\n",
    "for i in range(10):\n",
    "    graph = next(iter(dataloader_one))[0]\n",
    "    image_id = graph.image_id\n",
    "    # adapt to your local directory\n",
    "    IMAGE_DIR = '/local/home/jthomm/GraphCLIP/datasets/visual_genome/raw/VG/'\n",
    "    image = Image.open(IMAGE_DIR + str(image_id) + '.jpg')\n",
    "    images.append(image)\n",
    "    graphs.append(graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ViT finetuned models: For each graph you evaluate they give you a relationship probability confidence and an attribute probability confidence. Both are the mean confidences for the relationships and attributes of the graph you give in.\n",
    "\n",
    "In many graphs, there are no attributes, in this case, 'noattributes' os given back instead of a numerical score. Same behaviour for edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rel_scores': [0.9994899034500122, 0.373539000749588, 0.9996170997619629, 0.9842625856399536, 0.9885568618774414, 0.9755674600601196, 0.6376704573631287, 0.026969363912940025, 0.21289777755737305, 0.9988219141960144], 'attr_scores': [0.8067951202392578, 0.4739965498447418, 0.2303416132926941, 'noattributes', 0.5559964776039124, 'noattributes', 0.21760836243629456, 0.16305029392242432, 'noattributes', 'noattributes']}\n",
      "dict_keys(['rel_scores', 'attr_scores'])\n"
     ]
    }
   ],
   "source": [
    "scores = evaluator(images,graphs)\n",
    "print(scores)\n",
    "print(scores.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaltestenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
